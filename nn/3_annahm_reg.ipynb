{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset_1h, train_labels_1h = reformat(train_dataset, train_labels)\n",
    "valid_dataset_1, valid_labels_1h = reformat(valid_dataset, valid_labels)\n",
    "test_dataset_1h, test_labels_1h = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From Assignment 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "def LR_train(n_samples, C, train_ds, train_lbl, test_ds, test_lbl):\n",
    "\n",
    "    Xtrain = np.array(train_ds[0:n_samples,:,:])\n",
    "    Xtrain = np.reshape(Xtrain, (n_samples,784))\n",
    "    ytrain = np.reshape(train_lbl[0:n_samples], (n_samples,))\n",
    "    logreg = LogisticRegression(C=C,solver='sag', multi_class='ovr')\n",
    "    #gauss_wgts = np.random.normal(loc=0, scale=0.2, size=n_samples)\n",
    "    logreg.fit(Xtrain, ytrain)\n",
    "    \n",
    "    testX = np.reshape(test_ds, (len(test_ds), 784))\n",
    "    ypred = logreg.predict(testX)\n",
    "    \n",
    "    yresp = np.reshape(test_lbl, (len(test_lbl,)))\n",
    "    \n",
    "    return metrics.accuracy_score(yresp, ypred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854\n"
     ]
    }
   ],
   "source": [
    "print(LR_train(1000, .09, train_dataset, train_labels, test_dataset, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.006\n",
      "0.011\n",
      "0.016\n",
      "0.021\n",
      "0.026\n",
      "0.031\n",
      "0.036\n",
      "0.041\n",
      "0.046\n",
      "0.051\n",
      "0.056\n",
      "0.061\n",
      "0.066\n",
      "0.071\n",
      "0.076\n",
      "0.081\n",
      "0.086\n",
      "0.091\n",
      "0.096\n",
      "0.101\n",
      "0.106\n",
      "0.111\n",
      "0.116\n",
      "0.121\n",
      "0.126\n",
      "0.131\n",
      "0.136\n",
      "0.141\n",
      "0.146\n",
      "0.151\n",
      "0.156\n",
      "0.161\n",
      "0.166\n",
      "0.171\n",
      "0.176\n",
      "0.181\n",
      "0.186\n",
      "0.191\n",
      "0.196\n",
      "0.201\n",
      "0.206\n",
      "0.211\n",
      "0.216\n",
      "0.221\n",
      "0.226\n",
      "0.231\n",
      "0.236\n",
      "0.241\n",
      "0.246\n",
      "0.251\n",
      "0.256\n",
      "0.261\n",
      "0.266\n",
      "0.271\n",
      "0.276\n",
      "0.281\n",
      "0.286\n",
      "0.291\n",
      "0.296\n",
      "0.301\n",
      "0.306\n",
      "0.311\n",
      "0.316\n",
      "0.321\n",
      "0.326\n",
      "0.331\n",
      "0.336\n",
      "0.341\n",
      "0.346\n",
      "0.351\n",
      "0.356\n",
      "0.361\n",
      "0.366\n",
      "0.371\n",
      "0.376\n",
      "0.381\n",
      "0.386\n",
      "0.391\n",
      "0.396\n",
      "0.401\n",
      "0.406\n",
      "0.411\n",
      "0.416\n",
      "0.421\n",
      "0.426\n",
      "0.431\n",
      "0.436\n",
      "0.441\n",
      "0.446\n",
      "0.451\n",
      "0.456\n",
      "0.461\n",
      "0.466\n",
      "0.471\n",
      "0.476\n",
      "0.481\n",
      "0.486\n",
      "0.491\n",
      "0.496\n",
      "0.501\n",
      "0.506\n",
      "0.511\n",
      "0.516\n",
      "0.521\n",
      "0.526\n",
      "0.531\n",
      "0.536\n",
      "0.541\n",
      "0.546\n",
      "0.551\n",
      "0.556\n",
      "0.561\n",
      "0.566\n",
      "0.571\n",
      "0.576\n",
      "0.581\n",
      "0.586\n",
      "0.591\n",
      "0.596\n",
      "0.601\n",
      "0.606\n",
      "0.611\n",
      "0.616\n",
      "0.621\n",
      "0.626\n",
      "0.631\n",
      "0.636\n",
      "0.641\n",
      "0.646\n",
      "0.651\n",
      "0.656\n",
      "0.661\n",
      "0.666\n",
      "0.671\n",
      "0.676\n",
      "0.681\n",
      "0.686\n",
      "0.691\n",
      "0.696\n",
      "0.701\n",
      "0.706\n",
      "0.711\n",
      "0.716\n",
      "0.721\n",
      "0.726\n",
      "0.731\n",
      "0.736\n",
      "0.741\n",
      "0.746\n",
      "0.751\n",
      "0.756\n",
      "0.761\n",
      "0.766\n",
      "0.771\n",
      "0.776\n",
      "0.781\n",
      "0.786\n",
      "0.791\n",
      "0.796\n",
      "0.801\n",
      "0.806\n",
      "0.811\n",
      "0.816\n",
      "0.821\n",
      "0.826\n",
      "0.831\n",
      "0.836\n",
      "0.841\n",
      "0.846\n",
      "0.851\n",
      "0.856\n",
      "0.861\n",
      "0.866\n",
      "0.871\n",
      "0.876\n",
      "0.881\n",
      "0.886\n",
      "0.891\n",
      "0.896\n",
      "0.901\n",
      "0.906\n",
      "0.911\n",
      "0.916\n",
      "0.921\n",
      "0.926\n",
      "0.931\n",
      "0.936\n",
      "0.941\n",
      "0.946\n",
      "0.951\n",
      "0.956\n",
      "0.961\n",
      "0.966\n",
      "0.971\n",
      "0.976\n",
      "0.981\n",
      "0.986\n",
      "0.991\n",
      "0.996\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for c_val in np.arange(0.001, 1.0, .005):\n",
    "    #print(c_val)    \n",
    "    acc = LR_train(1000, c_val, train_dataset, train_labels, test_dataset, test_labels)\n",
    "    accuracy_scores.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy 0.8599\n",
      "index 5\n",
      "[ 0.001  0.006  0.011  0.016  0.021  0.026  0.031  0.036]\n",
      "[0.82550000000000001, 0.85219999999999996, 0.85709999999999997, 0.85880000000000001, 0.85970000000000002, 0.8599, 0.85950000000000004, 0.85860000000000003]\n"
     ]
    }
   ],
   "source": [
    "print('max accuracy', max(accuracy_scores))\n",
    "print('index',accuracy_scores.index(max(accuracy_scores)))\n",
    "print(np.arange(.001,1.0,.005)[0:8])\n",
    "print(accuracy_scores[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_scores_1 = []\n",
    "for c_val in np.arange(0.022, .031, .0001):\n",
    "    #print(c_val)    \n",
    "    acc = LR_train(1000, c_val, train_dataset, train_labels, test_dataset, test_labels)\n",
    "    accuracy_scores_1.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4e924d75d0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBRER2UpJQUREtlJSEBGRrf4fzywga8SXfZkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e92618290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(.001, 1.0, .005), accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4e92437fd0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD7CAYAAABADhLcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRVEiERGRovx/H21dU5j7jcgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e9265aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(.022, .031, .0001), accuracy_scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy 0.8604\n",
      "index 28\n",
      "[ 0.024   0.0241  0.0242  0.0243  0.0244  0.0245  0.0246  0.0247  0.0248\n",
      "  0.0249]\n",
      "[0.85999999999999999, 0.86009999999999998, 0.86019999999999996, 0.86009999999999998, 0.86009999999999998, 0.86009999999999998, 0.86019999999999996, 0.86029999999999995, 0.86040000000000005, 0.86040000000000005]\n"
     ]
    }
   ],
   "source": [
    "print('max accuracy', max(accuracy_scores_1))\n",
    "print('index',accuracy_scores_1.index(max(accuracy_scores_1)))\n",
    "print(np.arange(.022,.031,.0001)[20:30])\n",
    "print(accuracy_scores_1[20:30])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy = .8604  C = .0247, N_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Training and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMAGE_PIXELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-1bc15bd55970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# because batch_size was 128 and the test set dimension was much larger (10000, 784)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# then I saw that the tutorial used None instead and that worked for everything\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimages_placeholder\u001b[0m     \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_PIXELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mlabels_placeholder\u001b[0m     \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlabels_placeholder_int\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IMAGE_PIXELS' is not defined"
     ]
    }
   ],
   "source": [
    "graphn = tf.Graph()\n",
    "\n",
    "with graphn.as_default():\n",
    "    # Inputs and PLACEHOLDERS\n",
    "    # Originally set the shape for each of these to specifically use batch_size for # rows\n",
    "    # This caused problems when I wanted to run the entire test set to get an accuracy score\n",
    "    # because batch_size was 128 and the test set dimension was much larger (10000, 784)\n",
    "    # then I saw that the tutorial used None instead and that worked for everything\n",
    "    images_placeholder     =tf.placeholder(tf.float32, shape=(None, IMAGE_PIXELS))\n",
    "    labels_placeholder     =tf.placeholder(tf.float32, shape=(None, NUM_CLASSES))\n",
    "    labels_placeholder_int =tf.placeholder(tf.int32, shape=(None))  \n",
    "   \n",
    "    # INFERENCE\n",
    "    with tf.name_scope('hidden1') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal([IMAGE_PIXELS, hidden1_units], \n",
    "            stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))), name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden1_units]), name = 'biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(images_placeholder, weights) + biases)\n",
    "\n",
    "    with tf.name_scope('hidden2') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal([hidden1_units, hidden2_units],\n",
    "            stddev=1.0 / math.sqrt(float(hidden1_units))), name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden2_units]), name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "\n",
    "    with tf.name_scope('softmax_linear') as scope:\n",
    "        weights = tf.Variable(tf.truncated_normal([hidden2_units, NUM_CLASSES],\n",
    "            stddev=1.0 / math.sqrt(float(hidden2_units))),name='weights')\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]),name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    "      \n",
    "    # LOSS\n",
    "    # softmax_cross_entropy needs labels_placeholder to be float32 1hot encoded\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels_placeholder))\n",
    "    \n",
    "    # TRAINING\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    # EVAL (use either eval_acc op or the eval_correct op)\n",
    "    # Gets the index of the largest value across the tensor, test_a is prediction, test_b is response\n",
    "    test_a = tf.argmax(logits,1)\n",
    "    test_b = tf.argmax(labels_placeholder,1)\n",
    "    # Boolean tensor\n",
    "    correct_prediction = tf.equal(test_a, test_b)\n",
    "    cast_float = tf.cast(correct_prediction, tf.float32)\n",
    "    # Get mean across tensor, ie sum/length\n",
    "    eval_acc = tf.reduce_mean(cast_float)\n",
    "    # in_top_k requires labels_placeholder to be int32 or int64 list\n",
    "    correct = tf.nn.in_top_k(logits, labels_placeholder_int, 1)\n",
    "    eval_correct = tf.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING LOOP\n",
    "\n",
    "with tf.Session(graph=graphn) as session:\n",
    "    init = tf.initialize_all_variables().run()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    for step in xrange(max_steps):\n",
    "        # Generates the starting index from train_dataset to extract the minibatch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        batch_labels_int = train_labels_int[offset:(offset + batch_size)]\n",
    "        # A) The fact that I only feed it labels_placeholder and not labels_placeholder_int?\n",
    "        feed_dict = {images_placeholder : batch_data, labels_placeholder : batch_labels, labels_placeholder_int : batch_labels_int}\n",
    "        _, l, predictions, num_correct = session.run([train_op, loss, train_prediction, eval_correct], feed_dict=feed_dict)       \n",
    "        \n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            # Evaluate the entire dataset in specified batch-size increments, return all predictions\n",
    "            acc, eval_predictions = do_eval(valid_dataset, valid_labels, valid_labels_int, batch_size, \n",
    "                    images_placeholder, labels_placeholder, labels_placeholder_int)\n",
    "            print(\"Validation accuracy: %4.6f\" %(acc))\n",
    "    \n",
    "    fdict = {images_placeholder : test_dataset, \n",
    "             labels_placeholder : test_labels,\n",
    "             labels_placeholder_int : test_labels_int}\n",
    "    logits, eval_correct, test_acc = session.run([logits, eval_correct, eval_acc], feed_dict=fdict)\n",
    "    print('Test dataset accuracy %4.2f%%' %(100*eval_correct/float(len(test_dataset))))\n",
    "    \n",
    "    #print(sess.run(logits, feed_dict={images_placeholder: test_dataset,labels_placeholder: test_labels}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(valid_dataset, valid_labels, valid_labels_int, batch_size, \n",
    "            images_placeholder, labels_placeholder, labels_placeholder_int):\n",
    "    true_count = 0  # Counts the number of correct predictions.\n",
    "    steps_per_epoch = valid_dataset.shape[0] // batch_size\n",
    "    num_examples = steps_per_epoch * batch_size\n",
    "    eval_predictions = []\n",
    "    for step in xrange(steps_per_epoch):\n",
    "        eval_offset = (step * batch_size) % (valid_labels.shape[0] - batch_size)\n",
    "        eval_batch_data = valid_dataset[eval_offset:(eval_offset + batch_size), :]\n",
    "        eval_batch_labels = valid_labels[eval_offset:(eval_offset + batch_size), :]\n",
    "        eval_batch_labels_int = valid_labels_int[eval_offset:(eval_offset + batch_size)]\n",
    "        f_dict = {images_placeholder : eval_batch_data, labels_placeholder : eval_batch_labels,\n",
    "                  labels_placeholder_int : eval_batch_labels_int}\n",
    "        eval_predictions += session.run([eval_correct, loss, train_op], feed_dict=f_dict)\n",
    "    #print(\"validation accuracy: %4.6f%%\" %(100*sum(eval_predictions)/float(num_examples)))    \n",
    "    return 100*sum(eval_predictions)/float(num_examples), eval_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
